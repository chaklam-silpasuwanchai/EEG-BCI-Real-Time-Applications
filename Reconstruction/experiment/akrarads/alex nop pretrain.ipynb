{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class SemanticImageExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    This class expected image as input with size (64x64x3)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_class_num, feature_size=200, pretrain=False):\n",
    "        self.feature_size = feature_size\n",
    "        self.output_class_num = output_class_num\n",
    "        super(SemanticImageExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Alex1\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # Alex2\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # Alex3\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Alex4\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Alex5\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        # return the same number of features but change width and height of img\n",
    "\n",
    "        if(pretrain):\n",
    "            ori_alex = torchvision.models.alexnet(pretrained = True)\n",
    "            ori_weight = ori_alex.state_dict()\n",
    "            ori_weight.pop('classifier.1.weight')\n",
    "            ori_weight.pop('classifier.1.bias')\n",
    "            ori_weight.pop('classifier.4.weight')\n",
    "            ori_weight.pop('classifier.4.bias')\n",
    "            ori_weight.pop('classifier.6.weight')\n",
    "            ori_weight.pop('classifier.6.bias')\n",
    "            self.load_state_dict(ori_weight)\n",
    "            del(ori_alex)\n",
    "            del(ori_weight)\n",
    "        # finally\n",
    "        self.add_classifier()\n",
    "\n",
    "\n",
    "    def add_classifier(self):\n",
    "        self.fc06 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc07 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, self.feature_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc08 = nn.Sequential(\n",
    "            nn.Linear(self.feature_size, self.output_class_num),\n",
    "            nn.Softmax())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc06(x)\n",
    "        semantic_features = self.fc07(x)\n",
    "        p_label = self.fc08(semantic_features)\n",
    "        return semantic_features, p_label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "nop_alex = SemanticImageExtractor(output_class_num=6, pretrain='./weights/original_alex_no_classifier.pth')\n",
    "nop_alex.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SemanticImageExtractor(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (fc06): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc07): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=4096, out_features=200, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc08): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=6, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# def custom_loader(model, state_dict):\n",
    "#     # Copy from https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py\n",
    "#     missing_keys: List[str] = []\n",
    "#     unexpected_keys: List[str] = []\n",
    "#     error_msgs: List[str] = []\n",
    "\n",
    "#     # copy state_dict so _load_from_state_dict can modify it\n",
    "#     metadata = getattr(state_dict, '_metadata', None)\n",
    "#     print(metadata)\n",
    "#     state_dict = state_dict.copy()\n",
    "#     if metadata is not None:\n",
    "#         # mypy isn't aware that \"_metadata\" exists in state_dict\n",
    "#         state_dict._metadata = metadata  # type: ignore[attr-defined]\n",
    "\n",
    "#     def load(module, prefix=''):\n",
    "#         local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
    "#         module._load_from_state_dict(\n",
    "#             state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "#         for name, child in module._modules.items():\n",
    "#             if child is not None:\n",
    "#                 load(child, prefix + name + '.')\n",
    "#     load(model)\n",
    "#     pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "nop_alex = SemanticImageExtractor(output_class_num=6)\n",
    "# custom_loader(nop_alex, torch.load('./weights/original_alex.pth'))\n",
    "nop_alex.eval()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OrderedDict([('', {'version': 1}), ('features', {'version': 1}), ('features.0', {'version': 1}), ('features.1', {'version': 1}), ('features.2', {'version': 1}), ('features.3', {'version': 1}), ('features.4', {'version': 1}), ('features.5', {'version': 1}), ('features.6', {'version': 1}), ('features.7', {'version': 1}), ('features.8', {'version': 1}), ('features.9', {'version': 1}), ('features.10', {'version': 1}), ('features.11', {'version': 1}), ('features.12', {'version': 1}), ('avgpool', {'version': 1}), ('classifier', {'version': 1}), ('classifier.0', {'version': 1}), ('classifier.1', {'version': 1}), ('classifier.2', {'version': 1}), ('classifier.3', {'version': 1}), ('classifier.4', {'version': 1}), ('classifier.5', {'version': 1}), ('classifier.6', {'version': 1})])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SemanticImageExtractor(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (fc06): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc07): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=4096, out_features=200, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc08): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=6, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ori_alex = torchvision.models.alexnet(pretrained = True)\n",
    "ori_alex.classifier\n",
    "ori_alex.eval()\n",
    "# torch.save(ori_alex.state_dict(), './weights/original_alex.pth')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "ori_weight = ori_alex.state_dict()\n",
    "ori_weight.pop('classifier.1.weight')\n",
    "ori_weight.pop('classifier.1.bias')\n",
    "ori_weight.pop('classifier.4.weight')\n",
    "ori_weight.pop('classifier.4.bias')\n",
    "ori_weight.pop('classifier.6.weight')\n",
    "ori_weight.pop('classifier.6.bias')\n",
    "ori_weight.keys()\n",
    "torch.save(ori_weight, './weights/original_alex_no_classifier.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "nop_alex = SemanticImageExtractor(output_class_num=6)\n",
    "nop_alex.load_state_dict(torch.load('./weights/original_alex_no_classifier.pth'))\n",
    "nop_alex.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SemanticImageExtractor(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "nop_alex.fc06 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "nop_alex.fc07 = nn.Sequential(\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, nop_alex.feature_size),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "nop_alex.fc08 = nn.Sequential(\n",
    "    nn.Linear(nop_alex.feature_size, nop_alex.output_class_num),\n",
    "nn.Softmax()\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}