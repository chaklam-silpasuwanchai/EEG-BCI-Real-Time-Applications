{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "mean, std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "preprocess_augment = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = \"../../share_dataset/six_objects/stimuli_objects/\", transform=preprocess_augment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True , num_workers=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# for i in data_loader:\n",
    "#     print(i)\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = torchvision.models.alexnet(pretrained = False)\n",
    "\n",
    "model.classifier[6] = nn.Linear(in_features=4096,out_features=6,bias=True)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params_to_update = model.parameters()\n",
    "optimizer = optim.SGD(params_to_update , lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, weights_name='weight_save', is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    loss_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        # loss2 = criterion(aux4a, labels)\n",
    "                        # loss3 = criterion(aux4d, labels)\n",
    "                        loss = loss1 #+ (0.3 * loss2) + (0.3 * loss3)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # Backpropagate only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # Gather our summary statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_end = time.time()\n",
    "            \n",
    "            elapsed_epoch = epoch_end - epoch_start\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print(\"Epoch time taken: \", elapsed_epoch)\n",
    "\n",
    "            # If this is the best model on the validation set so far, deep copy it\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), weights_name + \".pth\")\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            if phase == 'train':\n",
    "                loss_acc_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Output summary statistics, load the best weight set, and return results\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, loss_acc_history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dataloaders = { 'train': data_loader}\n",
    "best_model, val_acc_history, loss_acc_history = train_model(model, dataloaders, criterion, optimizer, 9000, 'google_softmax_lr_0.001_bestsofar', is_inception=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/8999\n",
      "----------\n",
      "train Loss: 1.7924 Acc: 0.1583\n",
      "Epoch time taken:  0.5950281620025635\n",
      "\n",
      "Epoch 1/8999\n",
      "----------\n",
      "train Loss: 1.7921 Acc: 0.1667\n",
      "Epoch time taken:  0.6442277431488037\n",
      "\n",
      "Epoch 2/8999\n",
      "----------\n",
      "train Loss: 1.7919 Acc: 0.1667\n",
      "Epoch time taken:  0.596604585647583\n",
      "\n",
      "Epoch 3/8999\n",
      "----------\n",
      "train Loss: 1.7917 Acc: 0.1667\n",
      "Epoch time taken:  0.6810956001281738\n",
      "\n",
      "Epoch 4/8999\n",
      "----------\n",
      "train Loss: 1.7920 Acc: 0.1667\n",
      "Epoch time taken:  0.7555420398712158\n",
      "\n",
      "Epoch 5/8999\n",
      "----------\n",
      "train Loss: 1.7919 Acc: 0.1667\n",
      "Epoch time taken:  0.6826198101043701\n",
      "\n",
      "Epoch 6/8999\n",
      "----------\n",
      "train Loss: 1.7915 Acc: 0.1667\n",
      "Epoch time taken:  0.6393406391143799\n",
      "\n",
      "Epoch 7/8999\n",
      "----------\n",
      "train Loss: 1.7918 Acc: 0.1667\n",
      "Epoch time taken:  0.665916919708252\n",
      "\n",
      "Epoch 8/8999\n",
      "----------\n",
      "train Loss: 1.7917 Acc: 0.1667\n",
      "Epoch time taken:  0.6456997394561768\n",
      "\n",
      "Epoch 9/8999\n",
      "----------\n",
      "train Loss: 1.7916 Acc: 0.1667\n",
      "Epoch time taken:  0.648155927658081\n",
      "\n",
      "Epoch 10/8999\n",
      "----------\n",
      "train Loss: 1.7916 Acc: 0.1667\n",
      "Epoch time taken:  0.6134047508239746\n",
      "\n",
      "Epoch 11/8999\n",
      "----------\n",
      "train Loss: 1.7914 Acc: 0.1667\n",
      "Epoch time taken:  0.6204686164855957\n",
      "\n",
      "Epoch 12/8999\n",
      "----------\n",
      "train Loss: 1.7911 Acc: 0.1667\n",
      "Epoch time taken:  0.6660559177398682\n",
      "\n",
      "Epoch 13/8999\n",
      "----------\n",
      "train Loss: 1.7912 Acc: 0.1667\n",
      "Epoch time taken:  0.6055042743682861\n",
      "\n",
      "Epoch 14/8999\n",
      "----------\n",
      "train Loss: 1.7914 Acc: 0.1667\n",
      "Epoch time taken:  0.6369237899780273\n",
      "\n",
      "Epoch 15/8999\n",
      "----------\n",
      "train Loss: 1.7909 Acc: 0.1667\n",
      "Epoch time taken:  0.6616642475128174\n",
      "\n",
      "Epoch 16/8999\n",
      "----------\n",
      "train Loss: 1.7910 Acc: 0.1667\n",
      "Epoch time taken:  0.640099048614502\n",
      "\n",
      "Epoch 17/8999\n",
      "----------\n",
      "train Loss: 1.7909 Acc: 0.1667\n",
      "Epoch time taken:  0.6239135265350342\n",
      "\n",
      "Epoch 18/8999\n",
      "----------\n",
      "train Loss: 1.7911 Acc: 0.1667\n",
      "Epoch time taken:  0.6465601921081543\n",
      "\n",
      "Epoch 19/8999\n",
      "----------\n",
      "train Loss: 1.7909 Acc: 0.1667\n",
      "Epoch time taken:  0.6126995086669922\n",
      "\n",
      "Epoch 20/8999\n",
      "----------\n",
      "train Loss: 1.7903 Acc: 0.1667\n",
      "Epoch time taken:  0.706068754196167\n",
      "\n",
      "Epoch 21/8999\n",
      "----------\n",
      "train Loss: 1.7910 Acc: 0.1667\n",
      "Epoch time taken:  0.6378464698791504\n",
      "\n",
      "Epoch 22/8999\n",
      "----------\n",
      "train Loss: 1.7912 Acc: 0.1667\n",
      "Epoch time taken:  0.716726541519165\n",
      "\n",
      "Epoch 23/8999\n",
      "----------\n",
      "train Loss: 1.7909 Acc: 0.1667\n",
      "Epoch time taken:  0.6034328937530518\n",
      "\n",
      "Epoch 24/8999\n",
      "----------\n",
      "train Loss: 1.7904 Acc: 0.1667\n",
      "Epoch time taken:  0.6585257053375244\n",
      "\n",
      "Epoch 25/8999\n",
      "----------\n",
      "train Loss: 1.7905 Acc: 0.1667\n",
      "Epoch time taken:  0.6509966850280762\n",
      "\n",
      "Epoch 26/8999\n",
      "----------\n",
      "train Loss: 1.7911 Acc: 0.1667\n",
      "Epoch time taken:  0.6141378879547119\n",
      "\n",
      "Epoch 27/8999\n",
      "----------\n",
      "train Loss: 1.7902 Acc: 0.1667\n",
      "Epoch time taken:  0.657414436340332\n",
      "\n",
      "Epoch 28/8999\n",
      "----------\n",
      "train Loss: 1.7899 Acc: 0.1667\n",
      "Epoch time taken:  0.6238932609558105\n",
      "\n",
      "Epoch 29/8999\n",
      "----------\n",
      "train Loss: 1.7899 Acc: 0.1667\n",
      "Epoch time taken:  0.6372029781341553\n",
      "\n",
      "Epoch 30/8999\n",
      "----------\n",
      "train Loss: 1.7901 Acc: 0.1667\n",
      "Epoch time taken:  0.6811461448669434\n",
      "\n",
      "Epoch 31/8999\n",
      "----------\n",
      "train Loss: 1.7899 Acc: 0.1667\n",
      "Epoch time taken:  0.6841936111450195\n",
      "\n",
      "Epoch 32/8999\n",
      "----------\n",
      "train Loss: 1.7893 Acc: 0.1667\n",
      "Epoch time taken:  0.6454477310180664\n",
      "\n",
      "Epoch 33/8999\n",
      "----------\n",
      "train Loss: 1.7896 Acc: 0.1667\n",
      "Epoch time taken:  0.6115932464599609\n",
      "\n",
      "Epoch 34/8999\n",
      "----------\n",
      "train Loss: 1.7892 Acc: 0.1667\n",
      "Epoch time taken:  0.6777365207672119\n",
      "\n",
      "Epoch 35/8999\n",
      "----------\n",
      "train Loss: 1.7893 Acc: 0.1667\n",
      "Epoch time taken:  0.6620845794677734\n",
      "\n",
      "Epoch 36/8999\n",
      "----------\n",
      "train Loss: 1.7893 Acc: 0.1667\n",
      "Epoch time taken:  0.6239094734191895\n",
      "\n",
      "Epoch 37/8999\n",
      "----------\n",
      "train Loss: 1.7891 Acc: 0.1667\n",
      "Epoch time taken:  0.6321702003479004\n",
      "\n",
      "Epoch 38/8999\n",
      "----------\n",
      "train Loss: 1.7893 Acc: 0.1667\n",
      "Epoch time taken:  0.6535413265228271\n",
      "\n",
      "Epoch 39/8999\n",
      "----------\n",
      "train Loss: 1.7894 Acc: 0.1667\n",
      "Epoch time taken:  0.6727039813995361\n",
      "\n",
      "Epoch 40/8999\n",
      "----------\n",
      "train Loss: 1.7889 Acc: 0.1667\n",
      "Epoch time taken:  0.6682391166687012\n",
      "\n",
      "Epoch 41/8999\n",
      "----------\n",
      "train Loss: 1.7885 Acc: 0.1667\n",
      "Epoch time taken:  0.6026146411895752\n",
      "\n",
      "Epoch 42/8999\n",
      "----------\n",
      "train Loss: 1.7884 Acc: 0.1667\n",
      "Epoch time taken:  0.667008638381958\n",
      "\n",
      "Epoch 43/8999\n",
      "----------\n",
      "train Loss: 1.7883 Acc: 0.1667\n",
      "Epoch time taken:  0.6493890285491943\n",
      "\n",
      "Epoch 44/8999\n",
      "----------\n",
      "train Loss: 1.7875 Acc: 0.1667\n",
      "Epoch time taken:  0.6479296684265137\n",
      "\n",
      "Epoch 45/8999\n",
      "----------\n",
      "train Loss: 1.7872 Acc: 0.1667\n",
      "Epoch time taken:  0.66300368309021\n",
      "\n",
      "Epoch 46/8999\n",
      "----------\n",
      "train Loss: 1.7867 Acc: 0.1667\n",
      "Epoch time taken:  0.6240234375\n",
      "\n",
      "Epoch 47/8999\n",
      "----------\n",
      "train Loss: 1.7872 Acc: 0.1667\n",
      "Epoch time taken:  0.6656696796417236\n",
      "\n",
      "Epoch 48/8999\n",
      "----------\n",
      "train Loss: 1.7868 Acc: 0.1667\n",
      "Epoch time taken:  0.6675305366516113\n",
      "\n",
      "Epoch 49/8999\n",
      "----------\n",
      "train Loss: 1.7869 Acc: 0.1667\n",
      "Epoch time taken:  0.598250150680542\n",
      "\n",
      "Epoch 50/8999\n",
      "----------\n",
      "train Loss: 1.7856 Acc: 0.1667\n",
      "Epoch time taken:  0.6306657791137695\n",
      "\n",
      "Epoch 51/8999\n",
      "----------\n",
      "train Loss: 1.7858 Acc: 0.1667\n",
      "Epoch time taken:  0.6561503410339355\n",
      "\n",
      "Epoch 52/8999\n",
      "----------\n",
      "train Loss: 1.7854 Acc: 0.1667\n",
      "Epoch time taken:  0.6611964702606201\n",
      "\n",
      "Epoch 53/8999\n",
      "----------\n",
      "train Loss: 1.7845 Acc: 0.1667\n",
      "Epoch time taken:  0.619818925857544\n",
      "\n",
      "Epoch 54/8999\n",
      "----------\n",
      "train Loss: 1.7838 Acc: 0.1667\n",
      "Epoch time taken:  0.6160767078399658\n",
      "\n",
      "Epoch 55/8999\n",
      "----------\n",
      "train Loss: 1.7835 Acc: 0.1667\n",
      "Epoch time taken:  0.630744457244873\n",
      "\n",
      "Epoch 56/8999\n",
      "----------\n",
      "train Loss: 1.7821 Acc: 0.1667\n",
      "Epoch time taken:  0.6229066848754883\n",
      "\n",
      "Epoch 57/8999\n",
      "----------\n",
      "train Loss: 1.7816 Acc: 0.1667\n",
      "Epoch time taken:  0.6784417629241943\n",
      "\n",
      "Epoch 58/8999\n",
      "----------\n",
      "train Loss: 1.7815 Acc: 0.1667\n",
      "Epoch time taken:  0.6790142059326172\n",
      "\n",
      "Epoch 59/8999\n",
      "----------\n",
      "train Loss: 1.7800 Acc: 0.1667\n",
      "Epoch time taken:  0.6140425205230713\n",
      "\n",
      "Epoch 60/8999\n",
      "----------\n",
      "train Loss: 1.7781 Acc: 0.1667\n",
      "Epoch time taken:  0.6163959503173828\n",
      "\n",
      "Epoch 61/8999\n",
      "----------\n",
      "train Loss: 1.7773 Acc: 0.1667\n",
      "Epoch time taken:  0.6901109218597412\n",
      "\n",
      "Epoch 62/8999\n",
      "----------\n",
      "train Loss: 1.7753 Acc: 0.1667\n",
      "Epoch time taken:  0.5901052951812744\n",
      "\n",
      "Epoch 63/8999\n",
      "----------\n",
      "train Loss: 1.7743 Acc: 0.1667\n",
      "Epoch time taken:  0.6622869968414307\n",
      "\n",
      "Epoch 64/8999\n",
      "----------\n",
      "train Loss: 1.7723 Acc: 0.1667\n",
      "Epoch time taken:  0.6286864280700684\n",
      "\n",
      "Epoch 65/8999\n",
      "----------\n",
      "train Loss: 1.7709 Acc: 0.1667\n",
      "Epoch time taken:  0.6221158504486084\n",
      "\n",
      "Epoch 66/8999\n",
      "----------\n",
      "train Loss: 1.7687 Acc: 0.1667\n",
      "Epoch time taken:  0.6454017162322998\n",
      "\n",
      "Epoch 67/8999\n",
      "----------\n",
      "train Loss: 1.7649 Acc: 0.1667\n",
      "Epoch time taken:  0.6936709880828857\n",
      "\n",
      "Epoch 68/8999\n",
      "----------\n",
      "train Loss: 1.7594 Acc: 0.1667\n",
      "Epoch time taken:  0.6250314712524414\n",
      "\n",
      "Epoch 69/8999\n",
      "----------\n",
      "train Loss: 1.7570 Acc: 0.1667\n",
      "Epoch time taken:  0.5990395545959473\n",
      "\n",
      "Epoch 70/8999\n",
      "----------\n",
      "train Loss: 1.7513 Acc: 0.1667\n",
      "Epoch time taken:  0.6992511749267578\n",
      "\n",
      "Epoch 71/8999\n",
      "----------\n",
      "train Loss: 1.7421 Acc: 0.1667\n",
      "Epoch time taken:  0.6706352233886719\n",
      "\n",
      "Epoch 72/8999\n",
      "----------\n",
      "train Loss: 1.7364 Acc: 0.1667\n",
      "Epoch time taken:  0.6781184673309326\n",
      "\n",
      "Epoch 73/8999\n",
      "----------\n",
      "train Loss: 1.7263 Acc: 0.1667\n",
      "Epoch time taken:  0.6996331214904785\n",
      "\n",
      "Epoch 74/8999\n",
      "----------\n",
      "train Loss: 1.7215 Acc: 0.1667\n",
      "Epoch time taken:  0.6258018016815186\n",
      "\n",
      "Epoch 75/8999\n",
      "----------\n",
      "train Loss: 1.7186 Acc: 0.1667\n",
      "Epoch time taken:  0.6196310520172119\n",
      "\n",
      "Epoch 76/8999\n",
      "----------\n",
      "train Loss: 1.7019 Acc: 0.1667\n",
      "Epoch time taken:  0.7407422065734863\n",
      "\n",
      "Epoch 77/8999\n",
      "----------\n",
      "train Loss: 1.6948 Acc: 0.1833\n",
      "Epoch time taken:  0.6551709175109863\n",
      "\n",
      "Epoch 78/8999\n",
      "----------\n",
      "train Loss: 1.6917 Acc: 0.1917\n",
      "Epoch time taken:  0.6770172119140625\n",
      "\n",
      "Epoch 79/8999\n",
      "----------\n",
      "train Loss: 1.6838 Acc: 0.2250\n",
      "Epoch time taken:  0.6609675884246826\n",
      "\n",
      "Epoch 80/8999\n",
      "----------\n",
      "train Loss: 1.6754 Acc: 0.3083\n",
      "Epoch time taken:  0.6741762161254883\n",
      "\n",
      "Epoch 81/8999\n",
      "----------\n",
      "train Loss: 1.6652 Acc: 0.3333\n",
      "Epoch time taken:  0.6394693851470947\n",
      "\n",
      "Epoch 82/8999\n",
      "----------\n",
      "train Loss: 1.6560 Acc: 0.3333\n",
      "Epoch time taken:  0.6755309104919434\n",
      "\n",
      "Epoch 83/8999\n",
      "----------\n",
      "train Loss: 1.6476 Acc: 0.3500\n",
      "Epoch time taken:  0.6490399837493896\n",
      "\n",
      "Epoch 84/8999\n",
      "----------\n",
      "train Loss: 1.6546 Acc: 0.3250\n",
      "Epoch time taken:  0.6197831630706787\n",
      "\n",
      "Epoch 85/8999\n",
      "----------\n",
      "train Loss: 1.6447 Acc: 0.3250\n",
      "Epoch time taken:  0.6113390922546387\n",
      "\n",
      "Epoch 86/8999\n",
      "----------\n",
      "train Loss: 1.6492 Acc: 0.3417\n",
      "Epoch time taken:  0.6173875331878662\n",
      "\n",
      "Epoch 87/8999\n",
      "----------\n",
      "train Loss: 1.6410 Acc: 0.3333\n",
      "Epoch time taken:  0.6718106269836426\n",
      "\n",
      "Epoch 88/8999\n",
      "----------\n",
      "train Loss: 1.6395 Acc: 0.3417\n",
      "Epoch time taken:  0.6542026996612549\n",
      "\n",
      "Epoch 89/8999\n",
      "----------\n",
      "train Loss: 1.6333 Acc: 0.3417\n",
      "Epoch time taken:  0.6610307693481445\n",
      "\n",
      "Epoch 90/8999\n",
      "----------\n",
      "train Loss: 1.6319 Acc: 0.3417\n",
      "Epoch time taken:  0.6586225032806396\n",
      "\n",
      "Epoch 91/8999\n",
      "----------\n",
      "train Loss: 1.6312 Acc: 0.3333\n",
      "Epoch time taken:  0.6087117195129395\n",
      "\n",
      "Epoch 92/8999\n",
      "----------\n",
      "train Loss: 1.6377 Acc: 0.2750\n",
      "Epoch time taken:  0.6109142303466797\n",
      "\n",
      "Epoch 93/8999\n",
      "----------\n",
      "train Loss: 1.6211 Acc: 0.3667\n",
      "Epoch time taken:  0.644301176071167\n",
      "\n",
      "Epoch 94/8999\n",
      "----------\n",
      "train Loss: 1.6201 Acc: 0.3500\n",
      "Epoch time taken:  0.6457743644714355\n",
      "\n",
      "Epoch 95/8999\n",
      "----------\n",
      "train Loss: 1.6172 Acc: 0.3417\n",
      "Epoch time taken:  0.6846120357513428\n",
      "\n",
      "Epoch 96/8999\n",
      "----------\n",
      "train Loss: 1.6164 Acc: 0.3583\n",
      "Epoch time taken:  0.6584677696228027\n",
      "\n",
      "Epoch 97/8999\n",
      "----------\n",
      "train Loss: 1.6134 Acc: 0.3500\n",
      "Epoch time taken:  0.6478345394134521\n",
      "\n",
      "Epoch 98/8999\n",
      "----------\n",
      "train Loss: 1.6129 Acc: 0.3333\n",
      "Epoch time taken:  0.6614046096801758\n",
      "\n",
      "Epoch 99/8999\n",
      "----------\n",
      "train Loss: 1.6183 Acc: 0.3417\n",
      "Epoch time taken:  0.6125833988189697\n",
      "\n",
      "Epoch 100/8999\n",
      "----------\n",
      "train Loss: 1.6171 Acc: 0.3500\n",
      "Epoch time taken:  0.6718378067016602\n",
      "\n",
      "Epoch 101/8999\n",
      "----------\n",
      "train Loss: 1.6128 Acc: 0.3500\n",
      "Epoch time taken:  0.6422719955444336\n",
      "\n",
      "Epoch 102/8999\n",
      "----------\n",
      "train Loss: 1.6142 Acc: 0.3667\n",
      "Epoch time taken:  0.6300826072692871\n",
      "\n",
      "Epoch 103/8999\n",
      "----------\n",
      "train Loss: 1.6074 Acc: 0.3333\n",
      "Epoch time taken:  0.6239650249481201\n",
      "\n",
      "Epoch 104/8999\n",
      "----------\n",
      "train Loss: 1.6129 Acc: 0.3417\n",
      "Epoch time taken:  0.6145415306091309\n",
      "\n",
      "Epoch 105/8999\n",
      "----------\n",
      "train Loss: 1.6083 Acc: 0.3417\n",
      "Epoch time taken:  0.6847867965698242\n",
      "\n",
      "Epoch 106/8999\n",
      "----------\n",
      "train Loss: 1.6023 Acc: 0.3417\n",
      "Epoch time taken:  0.6475481986999512\n",
      "\n",
      "Epoch 107/8999\n",
      "----------\n",
      "train Loss: 1.5966 Acc: 0.3333\n",
      "Epoch time taken:  0.689234733581543\n",
      "\n",
      "Epoch 108/8999\n",
      "----------\n",
      "train Loss: 1.5922 Acc: 0.3167\n",
      "Epoch time taken:  0.6329326629638672\n",
      "\n",
      "Epoch 109/8999\n",
      "----------\n",
      "train Loss: 1.6077 Acc: 0.3417\n",
      "Epoch time taken:  0.6951005458831787\n",
      "\n",
      "Epoch 110/8999\n",
      "----------\n",
      "train Loss: 1.6066 Acc: 0.3167\n",
      "Epoch time taken:  0.656379222869873\n",
      "\n",
      "Epoch 111/8999\n",
      "----------\n",
      "train Loss: 1.5853 Acc: 0.3417\n",
      "Epoch time taken:  0.6269445419311523\n",
      "\n",
      "Epoch 112/8999\n",
      "----------\n",
      "train Loss: 1.6079 Acc: 0.3417\n",
      "Epoch time taken:  0.6605274677276611\n",
      "\n",
      "Epoch 113/8999\n",
      "----------\n",
      "train Loss: 1.5966 Acc: 0.3167\n",
      "Epoch time taken:  0.6592648029327393\n",
      "\n",
      "Epoch 114/8999\n",
      "----------\n",
      "train Loss: 1.5865 Acc: 0.3500\n",
      "Epoch time taken:  0.6278665065765381\n",
      "\n",
      "Epoch 115/8999\n",
      "----------\n",
      "train Loss: 1.5941 Acc: 0.3750\n",
      "Epoch time taken:  0.615006685256958\n",
      "\n",
      "Epoch 116/8999\n",
      "----------\n",
      "train Loss: 1.5802 Acc: 0.3583\n",
      "Epoch time taken:  0.7232677936553955\n",
      "\n",
      "Epoch 117/8999\n",
      "----------\n",
      "train Loss: 1.5934 Acc: 0.3250\n",
      "Epoch time taken:  0.5914182662963867\n",
      "\n",
      "Epoch 118/8999\n",
      "----------\n",
      "train Loss: 1.5808 Acc: 0.3250\n",
      "Epoch time taken:  0.6369168758392334\n",
      "\n",
      "Epoch 119/8999\n",
      "----------\n",
      "train Loss: 1.5783 Acc: 0.3417\n",
      "Epoch time taken:  0.6482105255126953\n",
      "\n",
      "Epoch 120/8999\n",
      "----------\n",
      "train Loss: 1.5952 Acc: 0.2917\n",
      "Epoch time taken:  0.6363017559051514\n",
      "\n",
      "Epoch 121/8999\n",
      "----------\n",
      "train Loss: 1.5731 Acc: 0.3500\n",
      "Epoch time taken:  0.6096577644348145\n",
      "\n",
      "Epoch 122/8999\n",
      "----------\n",
      "train Loss: 1.5817 Acc: 0.3417\n",
      "Epoch time taken:  0.662034273147583\n",
      "\n",
      "Epoch 123/8999\n",
      "----------\n",
      "train Loss: 1.5710 Acc: 0.3083\n",
      "Epoch time taken:  0.6269514560699463\n",
      "\n",
      "Epoch 124/8999\n",
      "----------\n",
      "train Loss: 1.5726 Acc: 0.3583\n",
      "Epoch time taken:  0.6001834869384766\n",
      "\n",
      "Epoch 125/8999\n",
      "----------\n",
      "train Loss: 1.5696 Acc: 0.3333\n",
      "Epoch time taken:  0.6640357971191406\n",
      "\n",
      "Epoch 126/8999\n",
      "----------\n",
      "train Loss: 1.5631 Acc: 0.3083\n",
      "Epoch time taken:  0.6525723934173584\n",
      "\n",
      "Epoch 127/8999\n",
      "----------\n",
      "train Loss: 1.5561 Acc: 0.3667\n",
      "Epoch time taken:  0.6462640762329102\n",
      "\n",
      "Epoch 128/8999\n",
      "----------\n",
      "train Loss: 1.5762 Acc: 0.3167\n",
      "Epoch time taken:  0.6358377933502197\n",
      "\n",
      "Epoch 129/8999\n",
      "----------\n",
      "train Loss: 1.5591 Acc: 0.3583\n",
      "Epoch time taken:  0.651843786239624\n",
      "\n",
      "Epoch 130/8999\n",
      "----------\n",
      "train Loss: 1.5671 Acc: 0.3333\n",
      "Epoch time taken:  0.6427195072174072\n",
      "\n",
      "Epoch 131/8999\n",
      "----------\n",
      "train Loss: 1.5624 Acc: 0.3833\n",
      "Epoch time taken:  0.590207576751709\n",
      "\n",
      "Epoch 132/8999\n",
      "----------\n",
      "train Loss: 1.5612 Acc: 0.3083\n",
      "Epoch time taken:  0.6984398365020752\n",
      "\n",
      "Epoch 133/8999\n",
      "----------\n",
      "train Loss: 1.5632 Acc: 0.3583\n",
      "Epoch time taken:  0.6029510498046875\n",
      "\n",
      "Epoch 134/8999\n",
      "----------\n",
      "train Loss: 1.5497 Acc: 0.3500\n",
      "Epoch time taken:  0.5898523330688477\n",
      "\n",
      "Epoch 135/8999\n",
      "----------\n",
      "train Loss: 1.5460 Acc: 0.3250\n",
      "Epoch time taken:  0.6881930828094482\n",
      "\n",
      "Epoch 136/8999\n",
      "----------\n",
      "train Loss: 1.5482 Acc: 0.3667\n",
      "Epoch time taken:  0.6444485187530518\n",
      "\n",
      "Epoch 137/8999\n",
      "----------\n",
      "train Loss: 1.5574 Acc: 0.3500\n",
      "Epoch time taken:  0.5900816917419434\n",
      "\n",
      "Epoch 138/8999\n",
      "----------\n",
      "train Loss: 1.5545 Acc: 0.3333\n",
      "Epoch time taken:  0.677358865737915\n",
      "\n",
      "Epoch 139/8999\n",
      "----------\n",
      "train Loss: 1.5599 Acc: 0.3167\n",
      "Epoch time taken:  0.6369166374206543\n",
      "\n",
      "Epoch 140/8999\n",
      "----------\n",
      "train Loss: 1.5762 Acc: 0.3083\n",
      "Epoch time taken:  0.650676965713501\n",
      "\n",
      "Epoch 141/8999\n",
      "----------\n",
      "train Loss: 1.5424 Acc: 0.3583\n",
      "Epoch time taken:  0.6482470035552979\n",
      "\n",
      "Epoch 142/8999\n",
      "----------\n",
      "train Loss: 1.5471 Acc: 0.3333\n",
      "Epoch time taken:  0.6318662166595459\n",
      "\n",
      "Epoch 143/8999\n",
      "----------\n",
      "train Loss: 1.5426 Acc: 0.3500\n",
      "Epoch time taken:  0.6550507545471191\n",
      "\n",
      "Epoch 144/8999\n",
      "----------\n",
      "train Loss: 1.5259 Acc: 0.3417\n",
      "Epoch time taken:  0.6325957775115967\n",
      "\n",
      "Epoch 145/8999\n",
      "----------\n",
      "train Loss: 1.5405 Acc: 0.3500\n",
      "Epoch time taken:  0.6920809745788574\n",
      "\n",
      "Epoch 146/8999\n",
      "----------\n",
      "train Loss: 1.5334 Acc: 0.3583\n",
      "Epoch time taken:  0.6780579090118408\n",
      "\n",
      "Epoch 147/8999\n",
      "----------\n",
      "train Loss: 1.5431 Acc: 0.3417\n",
      "Epoch time taken:  0.6131410598754883\n",
      "\n",
      "Epoch 148/8999\n",
      "----------\n",
      "train Loss: 1.5298 Acc: 0.3833\n",
      "Epoch time taken:  0.6702184677124023\n",
      "\n",
      "Epoch 149/8999\n",
      "----------\n",
      "train Loss: 1.5396 Acc: 0.3417\n",
      "Epoch time taken:  0.6006519794464111\n",
      "\n",
      "Epoch 150/8999\n",
      "----------\n",
      "train Loss: 1.5297 Acc: 0.3917\n",
      "Epoch time taken:  0.7006139755249023\n",
      "\n",
      "Epoch 151/8999\n",
      "----------\n",
      "train Loss: 1.5511 Acc: 0.3000\n",
      "Epoch time taken:  0.6186800003051758\n",
      "\n",
      "Epoch 152/8999\n",
      "----------\n",
      "train Loss: 1.5316 Acc: 0.3500\n",
      "Epoch time taken:  0.6555895805358887\n",
      "\n",
      "Epoch 153/8999\n",
      "----------\n",
      "train Loss: 1.5325 Acc: 0.3250\n",
      "Epoch time taken:  0.6618986129760742\n",
      "\n",
      "Epoch 154/8999\n",
      "----------\n",
      "train Loss: 1.5248 Acc: 0.3500\n",
      "Epoch time taken:  0.6894333362579346\n",
      "\n",
      "Epoch 155/8999\n",
      "----------\n",
      "train Loss: 1.5296 Acc: 0.3583\n",
      "Epoch time taken:  0.6870009899139404\n",
      "\n",
      "Epoch 156/8999\n",
      "----------\n",
      "train Loss: 1.5179 Acc: 0.3667\n",
      "Epoch time taken:  0.6441693305969238\n",
      "\n",
      "Epoch 157/8999\n",
      "----------\n",
      "train Loss: 1.5341 Acc: 0.3250\n",
      "Epoch time taken:  0.7275190353393555\n",
      "\n",
      "Epoch 158/8999\n",
      "----------\n",
      "train Loss: 1.5253 Acc: 0.3417\n",
      "Epoch time taken:  0.6544430255889893\n",
      "\n",
      "Epoch 159/8999\n",
      "----------\n",
      "train Loss: 1.5103 Acc: 0.3667\n",
      "Epoch time taken:  0.6214570999145508\n",
      "\n",
      "Epoch 160/8999\n",
      "----------\n",
      "train Loss: 1.5175 Acc: 0.3333\n",
      "Epoch time taken:  0.633296012878418\n",
      "\n",
      "Epoch 161/8999\n",
      "----------\n",
      "train Loss: 1.5134 Acc: 0.3500\n",
      "Epoch time taken:  0.6770291328430176\n",
      "\n",
      "Epoch 162/8999\n",
      "----------\n",
      "train Loss: 1.5236 Acc: 0.3333\n",
      "Epoch time taken:  0.6208724975585938\n",
      "\n",
      "Epoch 163/8999\n",
      "----------\n",
      "train Loss: 1.5364 Acc: 0.2833\n",
      "Epoch time taken:  0.672356128692627\n",
      "\n",
      "Epoch 164/8999\n",
      "----------\n",
      "train Loss: 1.5410 Acc: 0.3167\n",
      "Epoch time taken:  0.659426212310791\n",
      "\n",
      "Epoch 165/8999\n",
      "----------\n",
      "train Loss: 1.5083 Acc: 0.4000\n",
      "Epoch time taken:  0.6418113708496094\n",
      "\n",
      "Epoch 166/8999\n",
      "----------\n",
      "train Loss: 1.5383 Acc: 0.3417\n",
      "Epoch time taken:  0.6220402717590332\n",
      "\n",
      "Epoch 167/8999\n",
      "----------\n",
      "train Loss: 1.5187 Acc: 0.3417\n",
      "Epoch time taken:  0.6867914199829102\n",
      "\n",
      "Epoch 168/8999\n",
      "----------\n",
      "train Loss: 1.4981 Acc: 0.3333\n",
      "Epoch time taken:  0.6365349292755127\n",
      "\n",
      "Epoch 169/8999\n",
      "----------\n",
      "train Loss: 1.5180 Acc: 0.4000\n",
      "Epoch time taken:  0.6071770191192627\n",
      "\n",
      "Epoch 170/8999\n",
      "----------\n",
      "train Loss: 1.5051 Acc: 0.3333\n",
      "Epoch time taken:  0.663597822189331\n",
      "\n",
      "Epoch 171/8999\n",
      "----------\n",
      "train Loss: 1.5112 Acc: 0.3500\n",
      "Epoch time taken:  0.6344258785247803\n",
      "\n",
      "Epoch 172/8999\n",
      "----------\n",
      "train Loss: 1.5221 Acc: 0.3417\n",
      "Epoch time taken:  0.635812520980835\n",
      "\n",
      "Epoch 173/8999\n",
      "----------\n",
      "train Loss: 1.4885 Acc: 0.3667\n",
      "Epoch time taken:  0.6685981750488281\n",
      "\n",
      "Epoch 174/8999\n",
      "----------\n",
      "train Loss: 1.4936 Acc: 0.3750\n",
      "Epoch time taken:  0.655632734298706\n",
      "\n",
      "Epoch 175/8999\n",
      "----------\n",
      "train Loss: 1.5026 Acc: 0.3500\n",
      "Epoch time taken:  0.6929976940155029\n",
      "\n",
      "Epoch 176/8999\n",
      "----------\n",
      "train Loss: 1.4876 Acc: 0.3667\n",
      "Epoch time taken:  0.6736009120941162\n",
      "\n",
      "Epoch 177/8999\n",
      "----------\n",
      "train Loss: 1.4895 Acc: 0.3417\n",
      "Epoch time taken:  0.6505799293518066\n",
      "\n",
      "Epoch 178/8999\n",
      "----------\n",
      "train Loss: 1.5119 Acc: 0.3750\n",
      "Epoch time taken:  0.6549367904663086\n",
      "\n",
      "Epoch 179/8999\n",
      "----------\n",
      "train Loss: 1.4902 Acc: 0.3167\n",
      "Epoch time taken:  0.648078441619873\n",
      "\n",
      "Epoch 180/8999\n",
      "----------\n",
      "train Loss: 1.4734 Acc: 0.3667\n",
      "Epoch time taken:  0.6270859241485596\n",
      "\n",
      "Epoch 181/8999\n",
      "----------\n",
      "train Loss: 1.4930 Acc: 0.3667\n",
      "Epoch time taken:  0.7019543647766113\n",
      "\n",
      "Epoch 182/8999\n",
      "----------\n",
      "train Loss: 1.5140 Acc: 0.3250\n",
      "Epoch time taken:  0.6326382160186768\n",
      "\n",
      "Epoch 183/8999\n",
      "----------\n",
      "train Loss: 1.4847 Acc: 0.3417\n",
      "Epoch time taken:  0.6289620399475098\n",
      "\n",
      "Epoch 184/8999\n",
      "----------\n",
      "train Loss: 1.4884 Acc: 0.3333\n",
      "Epoch time taken:  0.7127907276153564\n",
      "\n",
      "Epoch 185/8999\n",
      "----------\n",
      "train Loss: 1.4718 Acc: 0.3583\n",
      "Epoch time taken:  0.6905653476715088\n",
      "\n",
      "Epoch 186/8999\n",
      "----------\n",
      "train Loss: 1.4792 Acc: 0.3583\n",
      "Epoch time taken:  0.636845588684082\n",
      "\n",
      "Epoch 187/8999\n",
      "----------\n",
      "train Loss: 1.4934 Acc: 0.3583\n",
      "Epoch time taken:  0.5885634422302246\n",
      "\n",
      "Epoch 188/8999\n",
      "----------\n",
      "train Loss: 1.4894 Acc: 0.3083\n",
      "Epoch time taken:  0.6291615962982178\n",
      "\n",
      "Epoch 189/8999\n",
      "----------\n",
      "train Loss: 1.5009 Acc: 0.2917\n",
      "Epoch time taken:  0.6433424949645996\n",
      "\n",
      "Epoch 190/8999\n",
      "----------\n",
      "train Loss: 1.4863 Acc: 0.3417\n",
      "Epoch time taken:  0.8358042240142822\n",
      "\n",
      "Epoch 191/8999\n",
      "----------\n",
      "train Loss: 1.4831 Acc: 0.3500\n",
      "Epoch time taken:  0.6676123142242432\n",
      "\n",
      "Epoch 192/8999\n",
      "----------\n",
      "train Loss: 1.4747 Acc: 0.3750\n",
      "Epoch time taken:  0.667198657989502\n",
      "\n",
      "Epoch 193/8999\n",
      "----------\n",
      "train Loss: 1.4799 Acc: 0.3917\n",
      "Epoch time taken:  0.603764533996582\n",
      "\n",
      "Epoch 194/8999\n",
      "----------\n",
      "train Loss: 1.4855 Acc: 0.3750\n",
      "Epoch time taken:  0.7045130729675293\n",
      "\n",
      "Epoch 195/8999\n",
      "----------\n",
      "train Loss: 1.4827 Acc: 0.3750\n",
      "Epoch time taken:  0.6387205123901367\n",
      "\n",
      "Epoch 196/8999\n",
      "----------\n",
      "train Loss: 1.4761 Acc: 0.3917\n",
      "Epoch time taken:  0.6118812561035156\n",
      "\n",
      "Epoch 197/8999\n",
      "----------\n",
      "train Loss: 1.4630 Acc: 0.3833\n",
      "Epoch time taken:  0.737128496170044\n",
      "\n",
      "Epoch 198/8999\n",
      "----------\n",
      "train Loss: 1.4714 Acc: 0.3500\n",
      "Epoch time taken:  0.6074044704437256\n",
      "\n",
      "Epoch 199/8999\n",
      "----------\n",
      "train Loss: 1.4667 Acc: 0.3917\n",
      "Epoch time taken:  0.6342432498931885\n",
      "\n",
      "Epoch 200/8999\n",
      "----------\n",
      "train Loss: 1.4929 Acc: 0.3333\n",
      "Epoch time taken:  0.735999584197998\n",
      "\n",
      "Epoch 201/8999\n",
      "----------\n",
      "train Loss: 1.4792 Acc: 0.3417\n",
      "Epoch time taken:  0.6182184219360352\n",
      "\n",
      "Epoch 202/8999\n",
      "----------\n",
      "train Loss: 1.4992 Acc: 0.3333\n",
      "Epoch time taken:  0.6573336124420166\n",
      "\n",
      "Epoch 203/8999\n",
      "----------\n",
      "train Loss: 1.4704 Acc: 0.3750\n",
      "Epoch time taken:  0.629194974899292\n",
      "\n",
      "Epoch 204/8999\n",
      "----------\n",
      "train Loss: 1.4551 Acc: 0.4000\n",
      "Epoch time taken:  0.6531035900115967\n",
      "\n",
      "Epoch 205/8999\n",
      "----------\n",
      "train Loss: 1.4663 Acc: 0.3667\n",
      "Epoch time taken:  0.6317899227142334\n",
      "\n",
      "Epoch 206/8999\n",
      "----------\n",
      "train Loss: 1.4664 Acc: 0.3583\n",
      "Epoch time taken:  0.6410608291625977\n",
      "\n",
      "Epoch 207/8999\n",
      "----------\n",
      "train Loss: 1.4547 Acc: 0.3750\n",
      "Epoch time taken:  0.6369261741638184\n",
      "\n",
      "Epoch 208/8999\n",
      "----------\n",
      "train Loss: 1.4518 Acc: 0.3417\n",
      "Epoch time taken:  0.6271357536315918\n",
      "\n",
      "Epoch 209/8999\n",
      "----------\n",
      "train Loss: 1.4448 Acc: 0.3833\n",
      "Epoch time taken:  0.6492800712585449\n",
      "\n",
      "Epoch 210/8999\n",
      "----------\n",
      "train Loss: 1.4501 Acc: 0.3750\n",
      "Epoch time taken:  0.6302299499511719\n",
      "\n",
      "Epoch 211/8999\n",
      "----------\n",
      "train Loss: 1.4670 Acc: 0.3333\n",
      "Epoch time taken:  0.6234197616577148\n",
      "\n",
      "Epoch 212/8999\n",
      "----------\n",
      "train Loss: 1.4637 Acc: 0.3167\n",
      "Epoch time taken:  0.6875736713409424\n",
      "\n",
      "Epoch 213/8999\n",
      "----------\n",
      "train Loss: 1.4668 Acc: 0.3333\n",
      "Epoch time taken:  0.5989060401916504\n",
      "\n",
      "Epoch 214/8999\n",
      "----------\n",
      "train Loss: 1.4281 Acc: 0.3333\n",
      "Epoch time taken:  0.65966796875\n",
      "\n",
      "Epoch 215/8999\n",
      "----------\n",
      "train Loss: 1.4521 Acc: 0.4000\n",
      "Epoch time taken:  0.5959045886993408\n",
      "\n",
      "Epoch 216/8999\n",
      "----------\n",
      "train Loss: 1.4473 Acc: 0.3833\n",
      "Epoch time taken:  0.6594619750976562\n",
      "\n",
      "Epoch 217/8999\n",
      "----------\n",
      "train Loss: 1.4913 Acc: 0.3167\n",
      "Epoch time taken:  0.6495206356048584\n",
      "\n",
      "Epoch 218/8999\n",
      "----------\n",
      "train Loss: 1.4610 Acc: 0.3417\n",
      "Epoch time taken:  0.6089136600494385\n",
      "\n",
      "Epoch 219/8999\n",
      "----------\n",
      "train Loss: 1.4564 Acc: 0.3333\n",
      "Epoch time taken:  0.7109358310699463\n",
      "\n",
      "Epoch 220/8999\n",
      "----------\n",
      "train Loss: 1.4529 Acc: 0.3583\n",
      "Epoch time taken:  0.7357602119445801\n",
      "\n",
      "Epoch 221/8999\n",
      "----------\n",
      "train Loss: 1.4538 Acc: 0.3333\n",
      "Epoch time taken:  0.6023895740509033\n",
      "\n",
      "Epoch 222/8999\n",
      "----------\n",
      "train Loss: 1.4502 Acc: 0.3500\n",
      "Epoch time taken:  0.6841347217559814\n",
      "\n",
      "Epoch 223/8999\n",
      "----------\n",
      "train Loss: 1.4580 Acc: 0.3917\n",
      "Epoch time taken:  0.6853048801422119\n",
      "\n",
      "Epoch 224/8999\n",
      "----------\n",
      "train Loss: 1.4738 Acc: 0.3333\n",
      "Epoch time taken:  0.6067209243774414\n",
      "\n",
      "Epoch 225/8999\n",
      "----------\n",
      "train Loss: 1.4534 Acc: 0.3750\n",
      "Epoch time taken:  0.6839942932128906\n",
      "\n",
      "Epoch 226/8999\n",
      "----------\n",
      "train Loss: 1.4463 Acc: 0.3333\n",
      "Epoch time taken:  0.6734931468963623\n",
      "\n",
      "Epoch 227/8999\n",
      "----------\n",
      "train Loss: 1.4601 Acc: 0.3833\n",
      "Epoch time taken:  0.6942062377929688\n",
      "\n",
      "Epoch 228/8999\n",
      "----------\n",
      "train Loss: 1.4603 Acc: 0.3250\n",
      "Epoch time taken:  0.678743839263916\n",
      "\n",
      "Epoch 229/8999\n",
      "----------\n",
      "train Loss: 1.4466 Acc: 0.3250\n",
      "Epoch time taken:  0.6166746616363525\n",
      "\n",
      "Epoch 230/8999\n",
      "----------\n",
      "train Loss: 1.4527 Acc: 0.3417\n",
      "Epoch time taken:  0.7868533134460449\n",
      "\n",
      "Epoch 231/8999\n",
      "----------\n",
      "train Loss: 1.4412 Acc: 0.3000\n",
      "Epoch time taken:  0.6302130222320557\n",
      "\n",
      "Epoch 232/8999\n",
      "----------\n",
      "train Loss: 1.4389 Acc: 0.3583\n",
      "Epoch time taken:  0.6866288185119629\n",
      "\n",
      "Epoch 233/8999\n",
      "----------\n",
      "train Loss: 1.4687 Acc: 0.3333\n",
      "Epoch time taken:  0.7089436054229736\n",
      "\n",
      "Epoch 234/8999\n",
      "----------\n",
      "train Loss: 1.4565 Acc: 0.3417\n",
      "Epoch time taken:  0.6759054660797119\n",
      "\n",
      "Epoch 235/8999\n",
      "----------\n",
      "train Loss: 1.4491 Acc: 0.3750\n",
      "Epoch time taken:  0.6749889850616455\n",
      "\n",
      "Epoch 236/8999\n",
      "----------\n",
      "train Loss: 1.4530 Acc: 0.3667\n",
      "Epoch time taken:  0.6693465709686279\n",
      "\n",
      "Epoch 237/8999\n",
      "----------\n",
      "train Loss: 1.4270 Acc: 0.3500\n",
      "Epoch time taken:  0.623659610748291\n",
      "\n",
      "Epoch 238/8999\n",
      "----------\n",
      "train Loss: 1.4133 Acc: 0.3917\n",
      "Epoch time taken:  0.72165846824646\n",
      "\n",
      "Epoch 239/8999\n",
      "----------\n",
      "train Loss: 1.4308 Acc: 0.3917\n",
      "Epoch time taken:  0.6730847358703613\n",
      "\n",
      "Epoch 240/8999\n",
      "----------\n",
      "train Loss: 1.4241 Acc: 0.3917\n",
      "Epoch time taken:  0.7195374965667725\n",
      "\n",
      "Epoch 241/8999\n",
      "----------\n",
      "train Loss: 1.4191 Acc: 0.3750\n",
      "Epoch time taken:  0.703120231628418\n",
      "\n",
      "Epoch 242/8999\n",
      "----------\n",
      "train Loss: 1.4090 Acc: 0.4000\n",
      "Epoch time taken:  0.6541893482208252\n",
      "\n",
      "Epoch 243/8999\n",
      "----------\n",
      "train Loss: 1.4433 Acc: 0.3667\n",
      "Epoch time taken:  0.669395923614502\n",
      "\n",
      "Epoch 244/8999\n",
      "----------\n",
      "train Loss: 1.4554 Acc: 0.3333\n",
      "Epoch time taken:  0.7263906002044678\n",
      "\n",
      "Epoch 245/8999\n",
      "----------\n",
      "train Loss: 1.4277 Acc: 0.3500\n",
      "Epoch time taken:  0.7047619819641113\n",
      "\n",
      "Epoch 246/8999\n",
      "----------\n",
      "train Loss: 1.4381 Acc: 0.4167\n",
      "Epoch time taken:  0.6408698558807373\n",
      "\n",
      "Epoch 247/8999\n",
      "----------\n",
      "train Loss: 1.4303 Acc: 0.3417\n",
      "Epoch time taken:  0.6173381805419922\n",
      "\n",
      "Epoch 248/8999\n",
      "----------\n",
      "train Loss: 1.4334 Acc: 0.3750\n",
      "Epoch time taken:  0.6082363128662109\n",
      "\n",
      "Epoch 249/8999\n",
      "----------\n",
      "train Loss: 1.4245 Acc: 0.3750\n",
      "Epoch time taken:  0.6696946620941162\n",
      "\n",
      "Epoch 250/8999\n",
      "----------\n",
      "train Loss: 1.4509 Acc: 0.3750\n",
      "Epoch time taken:  0.6841127872467041\n",
      "\n",
      "Epoch 251/8999\n",
      "----------\n",
      "train Loss: 1.4282 Acc: 0.3583\n",
      "Epoch time taken:  0.7271640300750732\n",
      "\n",
      "Epoch 252/8999\n",
      "----------\n",
      "train Loss: 1.4234 Acc: 0.3417\n",
      "Epoch time taken:  0.6769087314605713\n",
      "\n",
      "Epoch 253/8999\n",
      "----------\n",
      "train Loss: 1.4041 Acc: 0.4500\n",
      "Epoch time taken:  0.6284997463226318\n",
      "\n",
      "Epoch 254/8999\n",
      "----------\n",
      "train Loss: 1.4326 Acc: 0.3833\n",
      "Epoch time taken:  0.6586513519287109\n",
      "\n",
      "Epoch 255/8999\n",
      "----------\n",
      "train Loss: 1.4159 Acc: 0.3750\n",
      "Epoch time taken:  0.6293554306030273\n",
      "\n",
      "Epoch 256/8999\n",
      "----------\n",
      "train Loss: 1.4225 Acc: 0.3167\n",
      "Epoch time taken:  0.6900918483734131\n",
      "\n",
      "Epoch 257/8999\n",
      "----------\n",
      "train Loss: 1.4335 Acc: 0.3250\n",
      "Epoch time taken:  0.6594364643096924\n",
      "\n",
      "Epoch 258/8999\n",
      "----------\n",
      "train Loss: 1.3968 Acc: 0.4167\n",
      "Epoch time taken:  0.637017011642456\n",
      "\n",
      "Epoch 259/8999\n",
      "----------\n",
      "train Loss: 1.4310 Acc: 0.3667\n",
      "Epoch time taken:  0.6555202007293701\n",
      "\n",
      "Epoch 260/8999\n",
      "----------\n",
      "train Loss: 1.4241 Acc: 0.3250\n",
      "Epoch time taken:  0.6589055061340332\n",
      "\n",
      "Epoch 261/8999\n",
      "----------\n",
      "train Loss: 1.4477 Acc: 0.3583\n",
      "Epoch time taken:  0.6733319759368896\n",
      "\n",
      "Epoch 262/8999\n",
      "----------\n",
      "train Loss: 1.4280 Acc: 0.4250\n",
      "Epoch time taken:  0.6183478832244873\n",
      "\n",
      "Epoch 263/8999\n",
      "----------\n",
      "train Loss: 1.4236 Acc: 0.3750\n",
      "Epoch time taken:  0.6233327388763428\n",
      "\n",
      "Epoch 264/8999\n",
      "----------\n",
      "train Loss: 1.4345 Acc: 0.3417\n",
      "Epoch time taken:  0.7070531845092773\n",
      "\n",
      "Epoch 265/8999\n",
      "----------\n",
      "train Loss: 1.4018 Acc: 0.4000\n",
      "Epoch time taken:  0.6462881565093994\n",
      "\n",
      "Epoch 266/8999\n",
      "----------\n",
      "train Loss: 1.4518 Acc: 0.3917\n",
      "Epoch time taken:  0.7271628379821777\n",
      "\n",
      "Epoch 267/8999\n",
      "----------\n",
      "train Loss: 1.4120 Acc: 0.3417\n",
      "Epoch time taken:  0.6709384918212891\n",
      "\n",
      "Epoch 268/8999\n",
      "----------\n",
      "train Loss: 1.4032 Acc: 0.3500\n",
      "Epoch time taken:  0.626117467880249\n",
      "\n",
      "Epoch 269/8999\n",
      "----------\n",
      "train Loss: 1.4388 Acc: 0.3500\n",
      "Epoch time taken:  0.6049942970275879\n",
      "\n",
      "Epoch 270/8999\n",
      "----------\n",
      "train Loss: 1.4048 Acc: 0.4083\n",
      "Epoch time taken:  0.6864485740661621\n",
      "\n",
      "Epoch 271/8999\n",
      "----------\n",
      "train Loss: 1.4194 Acc: 0.3583\n",
      "Epoch time taken:  0.5968484878540039\n",
      "\n",
      "Epoch 272/8999\n",
      "----------\n",
      "train Loss: 1.4144 Acc: 0.3667\n",
      "Epoch time taken:  0.6959817409515381\n",
      "\n",
      "Epoch 273/8999\n",
      "----------\n",
      "train Loss: 1.4221 Acc: 0.3500\n",
      "Epoch time taken:  0.7023324966430664\n",
      "\n",
      "Epoch 274/8999\n",
      "----------\n",
      "train Loss: 1.3984 Acc: 0.3833\n",
      "Epoch time taken:  0.6442115306854248\n",
      "\n",
      "Epoch 275/8999\n",
      "----------\n",
      "train Loss: 1.3975 Acc: 0.3667\n",
      "Epoch time taken:  0.6125211715698242\n",
      "\n",
      "Epoch 276/8999\n",
      "----------\n",
      "train Loss: 1.4000 Acc: 0.3333\n",
      "Epoch time taken:  0.6580414772033691\n",
      "\n",
      "Epoch 277/8999\n",
      "----------\n",
      "train Loss: 1.4120 Acc: 0.3500\n",
      "Epoch time taken:  0.6849641799926758\n",
      "\n",
      "Epoch 278/8999\n",
      "----------\n",
      "train Loss: 1.3814 Acc: 0.3500\n",
      "Epoch time taken:  0.6030826568603516\n",
      "\n",
      "Epoch 279/8999\n",
      "----------\n",
      "train Loss: 1.3997 Acc: 0.3667\n",
      "Epoch time taken:  0.6859757900238037\n",
      "\n",
      "Epoch 280/8999\n",
      "----------\n",
      "train Loss: 1.3914 Acc: 0.3917\n",
      "Epoch time taken:  0.6842122077941895\n",
      "\n",
      "Epoch 281/8999\n",
      "----------\n",
      "train Loss: 1.4064 Acc: 0.4000\n",
      "Epoch time taken:  0.7004547119140625\n",
      "\n",
      "Epoch 282/8999\n",
      "----------\n",
      "train Loss: 1.4251 Acc: 0.3667\n",
      "Epoch time taken:  0.7170059680938721\n",
      "\n",
      "Epoch 283/8999\n",
      "----------\n",
      "train Loss: 1.3904 Acc: 0.3583\n",
      "Epoch time taken:  0.6380453109741211\n",
      "\n",
      "Epoch 284/8999\n",
      "----------\n",
      "train Loss: 1.4081 Acc: 0.3417\n",
      "Epoch time taken:  0.6285579204559326\n",
      "\n",
      "Epoch 285/8999\n",
      "----------\n",
      "train Loss: 1.4290 Acc: 0.3750\n",
      "Epoch time taken:  0.699838399887085\n",
      "\n",
      "Epoch 286/8999\n",
      "----------\n",
      "train Loss: 1.3978 Acc: 0.3750\n",
      "Epoch time taken:  0.6260280609130859\n",
      "\n",
      "Epoch 287/8999\n",
      "----------\n",
      "train Loss: 1.3997 Acc: 0.3500\n",
      "Epoch time taken:  0.6401095390319824\n",
      "\n",
      "Epoch 288/8999\n",
      "----------\n",
      "train Loss: 1.3923 Acc: 0.3667\n",
      "Epoch time taken:  0.6865091323852539\n",
      "\n",
      "Epoch 289/8999\n",
      "----------\n",
      "train Loss: 1.3950 Acc: 0.3417\n",
      "Epoch time taken:  0.6919288635253906\n",
      "\n",
      "Epoch 290/8999\n",
      "----------\n",
      "train Loss: 1.3996 Acc: 0.4000\n",
      "Epoch time taken:  0.7090651988983154\n",
      "\n",
      "Epoch 291/8999\n",
      "----------\n",
      "train Loss: 1.3738 Acc: 0.3917\n",
      "Epoch time taken:  0.6532704830169678\n",
      "\n",
      "Epoch 292/8999\n",
      "----------\n",
      "train Loss: 1.4127 Acc: 0.3750\n",
      "Epoch time taken:  0.6434485912322998\n",
      "\n",
      "Epoch 293/8999\n",
      "----------\n",
      "train Loss: 1.3855 Acc: 0.4083\n",
      "Epoch time taken:  0.7099919319152832\n",
      "\n",
      "Epoch 294/8999\n",
      "----------\n",
      "train Loss: 1.3881 Acc: 0.4250\n",
      "Epoch time taken:  0.648287296295166\n",
      "\n",
      "Epoch 295/8999\n",
      "----------\n",
      "train Loss: 1.4050 Acc: 0.3667\n",
      "Epoch time taken:  0.6832740306854248\n",
      "\n",
      "Epoch 296/8999\n",
      "----------\n",
      "train Loss: 1.3812 Acc: 0.3917\n",
      "Epoch time taken:  0.6423156261444092\n",
      "\n",
      "Epoch 297/8999\n",
      "----------\n",
      "train Loss: 1.3857 Acc: 0.3750\n",
      "Epoch time taken:  0.587273359298706\n",
      "\n",
      "Epoch 298/8999\n",
      "----------\n",
      "train Loss: 1.3790 Acc: 0.3583\n",
      "Epoch time taken:  0.6714928150177002\n",
      "\n",
      "Epoch 299/8999\n",
      "----------\n",
      "train Loss: 1.4047 Acc: 0.4083\n",
      "Epoch time taken:  0.650198221206665\n",
      "\n",
      "Epoch 300/8999\n",
      "----------\n",
      "train Loss: 1.3606 Acc: 0.4083\n",
      "Epoch time taken:  0.604301929473877\n",
      "\n",
      "Epoch 301/8999\n",
      "----------\n",
      "train Loss: 1.3875 Acc: 0.3000\n",
      "Epoch time taken:  0.682844877243042\n",
      "\n",
      "Epoch 302/8999\n",
      "----------\n",
      "train Loss: 1.4001 Acc: 0.4083\n",
      "Epoch time taken:  0.6029953956604004\n",
      "\n",
      "Epoch 303/8999\n",
      "----------\n",
      "train Loss: 1.4221 Acc: 0.3417\n",
      "Epoch time taken:  0.6539990901947021\n",
      "\n",
      "Epoch 304/8999\n",
      "----------\n",
      "train Loss: 1.3863 Acc: 0.3583\n",
      "Epoch time taken:  0.6974446773529053\n",
      "\n",
      "Epoch 305/8999\n",
      "----------\n",
      "train Loss: 1.3906 Acc: 0.4417\n",
      "Epoch time taken:  0.6552209854125977\n",
      "\n",
      "Epoch 306/8999\n",
      "----------\n",
      "train Loss: 1.3627 Acc: 0.4750\n",
      "Epoch time taken:  0.7187116146087646\n",
      "\n",
      "Epoch 307/8999\n",
      "----------\n",
      "train Loss: 1.3969 Acc: 0.3333\n",
      "Epoch time taken:  0.6299123764038086\n",
      "\n",
      "Epoch 308/8999\n",
      "----------\n",
      "train Loss: 1.3759 Acc: 0.3500\n",
      "Epoch time taken:  0.6330292224884033\n",
      "\n",
      "Epoch 309/8999\n",
      "----------\n",
      "train Loss: 1.3759 Acc: 0.4500\n",
      "Epoch time taken:  0.6385090351104736\n",
      "\n",
      "Epoch 310/8999\n",
      "----------\n",
      "train Loss: 1.3811 Acc: 0.3750\n",
      "Epoch time taken:  0.7226650714874268\n",
      "\n",
      "Epoch 311/8999\n",
      "----------\n",
      "train Loss: 1.4070 Acc: 0.3583\n",
      "Epoch time taken:  0.6185376644134521\n",
      "\n",
      "Epoch 312/8999\n",
      "----------\n",
      "train Loss: 1.4226 Acc: 0.3583\n",
      "Epoch time taken:  0.6661772727966309\n",
      "\n",
      "Epoch 313/8999\n",
      "----------\n",
      "train Loss: 1.3987 Acc: 0.3583\n",
      "Epoch time taken:  0.6746959686279297\n",
      "\n",
      "Epoch 314/8999\n",
      "----------\n",
      "train Loss: 1.3841 Acc: 0.3917\n",
      "Epoch time taken:  0.663625955581665\n",
      "\n",
      "Epoch 315/8999\n",
      "----------\n",
      "train Loss: 1.3992 Acc: 0.3417\n",
      "Epoch time taken:  0.6616575717926025\n",
      "\n",
      "Epoch 316/8999\n",
      "----------\n",
      "train Loss: 1.4089 Acc: 0.4000\n",
      "Epoch time taken:  0.7396275997161865\n",
      "\n",
      "Epoch 317/8999\n",
      "----------\n",
      "train Loss: 1.3673 Acc: 0.4500\n",
      "Epoch time taken:  0.7089030742645264\n",
      "\n",
      "Epoch 318/8999\n",
      "----------\n",
      "train Loss: 1.3720 Acc: 0.3583\n",
      "Epoch time taken:  0.6476278305053711\n",
      "\n",
      "Epoch 319/8999\n",
      "----------\n",
      "train Loss: 1.3838 Acc: 0.3583\n",
      "Epoch time taken:  0.7728946208953857\n",
      "\n",
      "Epoch 320/8999\n",
      "----------\n",
      "train Loss: 1.3557 Acc: 0.3667\n",
      "Epoch time taken:  0.6121277809143066\n",
      "\n",
      "Epoch 321/8999\n",
      "----------\n",
      "train Loss: 1.3987 Acc: 0.4083\n",
      "Epoch time taken:  0.7329521179199219\n",
      "\n",
      "Epoch 322/8999\n",
      "----------\n",
      "train Loss: 1.4296 Acc: 0.3667\n",
      "Epoch time taken:  0.634152889251709\n",
      "\n",
      "Epoch 323/8999\n",
      "----------\n",
      "train Loss: 1.3904 Acc: 0.3667\n",
      "Epoch time taken:  0.6641466617584229\n",
      "\n",
      "Epoch 324/8999\n",
      "----------\n",
      "train Loss: 1.3837 Acc: 0.3333\n",
      "Epoch time taken:  0.6187155246734619\n",
      "\n",
      "Epoch 325/8999\n",
      "----------\n",
      "train Loss: 1.4099 Acc: 0.3750\n",
      "Epoch time taken:  0.6201372146606445\n",
      "\n",
      "Epoch 326/8999\n",
      "----------\n",
      "train Loss: 1.4021 Acc: 0.3417\n",
      "Epoch time taken:  0.7173798084259033\n",
      "\n",
      "Epoch 327/8999\n",
      "----------\n",
      "train Loss: 1.4142 Acc: 0.3417\n",
      "Epoch time taken:  0.6667261123657227\n",
      "\n",
      "Epoch 328/8999\n",
      "----------\n",
      "train Loss: 1.4076 Acc: 0.3833\n",
      "Epoch time taken:  0.6249821186065674\n",
      "\n",
      "Epoch 329/8999\n",
      "----------\n",
      "train Loss: 1.3755 Acc: 0.3417\n",
      "Epoch time taken:  0.7152352333068848\n",
      "\n",
      "Epoch 330/8999\n",
      "----------\n",
      "train Loss: 1.4119 Acc: 0.3417\n",
      "Epoch time taken:  0.6641309261322021\n",
      "\n",
      "Epoch 331/8999\n",
      "----------\n",
      "train Loss: 1.4053 Acc: 0.3917\n",
      "Epoch time taken:  0.6521973609924316\n",
      "\n",
      "Epoch 332/8999\n",
      "----------\n",
      "train Loss: 1.3769 Acc: 0.3750\n",
      "Epoch time taken:  0.6222403049468994\n",
      "\n",
      "Epoch 333/8999\n",
      "----------\n",
      "train Loss: 1.3736 Acc: 0.3917\n",
      "Epoch time taken:  0.6550998687744141\n",
      "\n",
      "Epoch 334/8999\n",
      "----------\n",
      "train Loss: 1.4008 Acc: 0.3500\n",
      "Epoch time taken:  0.6364011764526367\n",
      "\n",
      "Epoch 335/8999\n",
      "----------\n",
      "train Loss: 1.3969 Acc: 0.3917\n",
      "Epoch time taken:  0.6348223686218262\n",
      "\n",
      "Epoch 336/8999\n",
      "----------\n",
      "train Loss: 1.3912 Acc: 0.4083\n",
      "Epoch time taken:  0.6783256530761719\n",
      "\n",
      "Epoch 337/8999\n",
      "----------\n",
      "train Loss: 1.4153 Acc: 0.3583\n",
      "Epoch time taken:  0.6665806770324707\n",
      "\n",
      "Epoch 338/8999\n",
      "----------\n",
      "train Loss: 1.3753 Acc: 0.3583\n",
      "Epoch time taken:  0.7020776271820068\n",
      "\n",
      "Epoch 339/8999\n",
      "----------\n",
      "train Loss: 1.3478 Acc: 0.4000\n",
      "Epoch time taken:  0.6215040683746338\n",
      "\n",
      "Epoch 340/8999\n",
      "----------\n",
      "train Loss: 1.3991 Acc: 0.3833\n",
      "Epoch time taken:  0.6965696811676025\n",
      "\n",
      "Epoch 341/8999\n",
      "----------\n",
      "train Loss: 1.3633 Acc: 0.3583\n",
      "Epoch time taken:  0.6979117393493652\n",
      "\n",
      "Epoch 342/8999\n",
      "----------\n",
      "train Loss: 1.4029 Acc: 0.3583\n",
      "Epoch time taken:  0.6312716007232666\n",
      "\n",
      "Epoch 343/8999\n",
      "----------\n",
      "train Loss: 1.3806 Acc: 0.3667\n",
      "Epoch time taken:  0.6427097320556641\n",
      "\n",
      "Epoch 344/8999\n",
      "----------\n",
      "train Loss: 1.4036 Acc: 0.3583\n",
      "Epoch time taken:  0.6624982357025146\n",
      "\n",
      "Epoch 345/8999\n",
      "----------\n",
      "train Loss: 1.3691 Acc: 0.3333\n",
      "Epoch time taken:  0.6403210163116455\n",
      "\n",
      "Epoch 346/8999\n",
      "----------\n",
      "train Loss: 1.3685 Acc: 0.3750\n",
      "Epoch time taken:  0.6168694496154785\n",
      "\n",
      "Epoch 347/8999\n",
      "----------\n",
      "train Loss: 1.3700 Acc: 0.3667\n",
      "Epoch time taken:  0.6127855777740479\n",
      "\n",
      "Epoch 348/8999\n",
      "----------\n",
      "train Loss: 1.3693 Acc: 0.4083\n",
      "Epoch time taken:  0.6268453598022461\n",
      "\n",
      "Epoch 349/8999\n",
      "----------\n",
      "train Loss: 1.3682 Acc: 0.3750\n",
      "Epoch time taken:  0.6250097751617432\n",
      "\n",
      "Epoch 350/8999\n",
      "----------\n",
      "train Loss: 1.3914 Acc: 0.3500\n",
      "Epoch time taken:  0.7125816345214844\n",
      "\n",
      "Epoch 351/8999\n",
      "----------\n",
      "train Loss: 1.3811 Acc: 0.3833\n",
      "Epoch time taken:  0.665205717086792\n",
      "\n",
      "Epoch 352/8999\n",
      "----------\n",
      "train Loss: 1.3796 Acc: 0.3417\n",
      "Epoch time taken:  0.6331496238708496\n",
      "\n",
      "Epoch 353/8999\n",
      "----------\n",
      "train Loss: 1.4363 Acc: 0.2833\n",
      "Epoch time taken:  0.6363029479980469\n",
      "\n",
      "Epoch 354/8999\n",
      "----------\n",
      "train Loss: 1.3657 Acc: 0.4167\n",
      "Epoch time taken:  0.642554759979248\n",
      "\n",
      "Epoch 355/8999\n",
      "----------\n",
      "train Loss: 1.3701 Acc: 0.4583\n",
      "Epoch time taken:  0.6514983177185059\n",
      "\n",
      "Epoch 356/8999\n",
      "----------\n",
      "train Loss: 1.3960 Acc: 0.3333\n",
      "Epoch time taken:  0.6150250434875488\n",
      "\n",
      "Epoch 357/8999\n",
      "----------\n",
      "train Loss: 1.3502 Acc: 0.3833\n",
      "Epoch time taken:  0.6464416980743408\n",
      "\n",
      "Epoch 358/8999\n",
      "----------\n",
      "train Loss: 1.3637 Acc: 0.4167\n",
      "Epoch time taken:  0.666024923324585\n",
      "\n",
      "Epoch 359/8999\n",
      "----------\n",
      "train Loss: 1.3698 Acc: 0.4000\n",
      "Epoch time taken:  0.6623847484588623\n",
      "\n",
      "Epoch 360/8999\n",
      "----------\n",
      "train Loss: 1.3954 Acc: 0.3833\n",
      "Epoch time taken:  0.6747493743896484\n",
      "\n",
      "Epoch 361/8999\n",
      "----------\n",
      "train Loss: 1.3858 Acc: 0.3667\n",
      "Epoch time taken:  0.6209800243377686\n",
      "\n",
      "Epoch 362/8999\n",
      "----------\n",
      "train Loss: 1.4028 Acc: 0.3750\n",
      "Epoch time taken:  0.5943150520324707\n",
      "\n",
      "Epoch 363/8999\n",
      "----------\n",
      "train Loss: 1.3993 Acc: 0.3750\n",
      "Epoch time taken:  0.6559960842132568\n",
      "\n",
      "Epoch 364/8999\n",
      "----------\n",
      "train Loss: 1.3629 Acc: 0.3833\n",
      "Epoch time taken:  0.614647626876831\n",
      "\n",
      "Epoch 365/8999\n",
      "----------\n",
      "train Loss: 1.3804 Acc: 0.3750\n",
      "Epoch time taken:  0.6846065521240234\n",
      "\n",
      "Epoch 366/8999\n",
      "----------\n",
      "train Loss: 1.3547 Acc: 0.4083\n",
      "Epoch time taken:  0.6085669994354248\n",
      "\n",
      "Epoch 367/8999\n",
      "----------\n",
      "train Loss: 1.3786 Acc: 0.3750\n",
      "Epoch time taken:  0.6245808601379395\n",
      "\n",
      "Epoch 368/8999\n",
      "----------\n",
      "train Loss: 1.3914 Acc: 0.4333\n",
      "Epoch time taken:  0.7276439666748047\n",
      "\n",
      "Epoch 369/8999\n",
      "----------\n",
      "train Loss: 1.3579 Acc: 0.3750\n",
      "Epoch time taken:  0.6203534603118896\n",
      "\n",
      "Epoch 370/8999\n",
      "----------\n",
      "train Loss: 1.3434 Acc: 0.4000\n",
      "Epoch time taken:  0.6322507858276367\n",
      "\n",
      "Epoch 371/8999\n",
      "----------\n",
      "train Loss: 1.3667 Acc: 0.3750\n",
      "Epoch time taken:  0.7279589176177979\n",
      "\n",
      "Epoch 372/8999\n",
      "----------\n",
      "train Loss: 1.3713 Acc: 0.3500\n",
      "Epoch time taken:  0.6512138843536377\n",
      "\n",
      "Epoch 373/8999\n",
      "----------\n",
      "train Loss: 1.3837 Acc: 0.3417\n",
      "Epoch time taken:  0.653923749923706\n",
      "\n",
      "Epoch 374/8999\n",
      "----------\n",
      "train Loss: 1.3509 Acc: 0.4167\n",
      "Epoch time taken:  0.5980918407440186\n",
      "\n",
      "Epoch 375/8999\n",
      "----------\n",
      "train Loss: 1.4065 Acc: 0.3667\n",
      "Epoch time taken:  0.7205040454864502\n",
      "\n",
      "Epoch 376/8999\n",
      "----------\n",
      "train Loss: 1.4020 Acc: 0.3833\n",
      "Epoch time taken:  0.636707067489624\n",
      "\n",
      "Epoch 377/8999\n",
      "----------\n",
      "train Loss: 1.3737 Acc: 0.3917\n",
      "Epoch time taken:  0.5638425350189209\n",
      "\n",
      "Epoch 378/8999\n",
      "----------\n",
      "train Loss: 1.3690 Acc: 0.3500\n",
      "Epoch time taken:  0.6017036437988281\n",
      "\n",
      "Epoch 379/8999\n",
      "----------\n",
      "train Loss: 1.3694 Acc: 0.3750\n",
      "Epoch time taken:  0.5657625198364258\n",
      "\n",
      "Epoch 380/8999\n",
      "----------\n",
      "train Loss: 1.3502 Acc: 0.3667\n",
      "Epoch time taken:  0.6583409309387207\n",
      "\n",
      "Epoch 381/8999\n",
      "----------\n",
      "train Loss: 1.3809 Acc: 0.3667\n",
      "Epoch time taken:  0.6929864883422852\n",
      "\n",
      "Epoch 382/8999\n",
      "----------\n",
      "train Loss: 1.3446 Acc: 0.3667\n",
      "Epoch time taken:  0.6597945690155029\n",
      "\n",
      "Epoch 383/8999\n",
      "----------\n",
      "train Loss: 1.3835 Acc: 0.3917\n",
      "Epoch time taken:  0.6736249923706055\n",
      "\n",
      "Epoch 384/8999\n",
      "----------\n",
      "train Loss: 1.3621 Acc: 0.3083\n",
      "Epoch time taken:  0.6321015357971191\n",
      "\n",
      "Epoch 385/8999\n",
      "----------\n",
      "train Loss: 1.3913 Acc: 0.3917\n",
      "Epoch time taken:  0.6525967121124268\n",
      "\n",
      "Epoch 386/8999\n",
      "----------\n",
      "train Loss: 1.3653 Acc: 0.4333\n",
      "Epoch time taken:  0.6635825634002686\n",
      "\n",
      "Epoch 387/8999\n",
      "----------\n",
      "train Loss: 1.3651 Acc: 0.3417\n",
      "Epoch time taken:  0.6079854965209961\n",
      "\n",
      "Epoch 388/8999\n",
      "----------\n",
      "train Loss: 1.3405 Acc: 0.4333\n",
      "Epoch time taken:  0.6206533908843994\n",
      "\n",
      "Epoch 389/8999\n",
      "----------\n",
      "train Loss: 1.3732 Acc: 0.3750\n",
      "Epoch time taken:  0.6689128875732422\n",
      "\n",
      "Epoch 390/8999\n",
      "----------\n",
      "train Loss: 1.3786 Acc: 0.3583\n",
      "Epoch time taken:  0.647554874420166\n",
      "\n",
      "Epoch 391/8999\n",
      "----------\n",
      "train Loss: 1.3285 Acc: 0.4083\n",
      "Epoch time taken:  0.6933605670928955\n",
      "\n",
      "Epoch 392/8999\n",
      "----------\n",
      "train Loss: 1.3511 Acc: 0.4333\n",
      "Epoch time taken:  0.6068456172943115\n",
      "\n",
      "Epoch 393/8999\n",
      "----------\n",
      "train Loss: 1.3575 Acc: 0.4500\n",
      "Epoch time taken:  0.6976206302642822\n",
      "\n",
      "Epoch 394/8999\n",
      "----------\n",
      "train Loss: 1.3653 Acc: 0.3417\n",
      "Epoch time taken:  0.6297540664672852\n",
      "\n",
      "Epoch 395/8999\n",
      "----------\n",
      "train Loss: 1.3238 Acc: 0.4083\n",
      "Epoch time taken:  0.6714355945587158\n",
      "\n",
      "Epoch 396/8999\n",
      "----------\n",
      "train Loss: 1.3781 Acc: 0.4000\n",
      "Epoch time taken:  0.6497001647949219\n",
      "\n",
      "Epoch 397/8999\n",
      "----------\n",
      "train Loss: 1.3443 Acc: 0.3750\n",
      "Epoch time taken:  0.6596195697784424\n",
      "\n",
      "Epoch 398/8999\n",
      "----------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}