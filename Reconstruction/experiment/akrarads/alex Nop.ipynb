{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "mean, std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "preprocess_augment = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = \"../../share_dataset/six_objects/stimuli_objects/\", transform=preprocess_augment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True , num_workers=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# for i in data_loader:\n",
    "#     print(i)\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class SemanticImageExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    This class expected image as input with size (64x64x3)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_class_num, feature_size=200):\n",
    "        super(SemanticImageExtractor, self).__init__()\n",
    "        self.alx_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.alx_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.alx_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.alx_layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.alx_layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        # return the same number of features but change width and height of img\n",
    "\n",
    "        self.fc06 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc07 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, feature_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc08 = nn.Sequential(\n",
    "            nn.Linear(feature_size, output_class_num),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alx_layer1(x)\n",
    "        x = self.alx_layer2(x)\n",
    "        x = self.alx_layer3(x)\n",
    "        x = self.alx_layer4(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc06(x)\n",
    "        semantic_features = self.fc07(x)\n",
    "        p_label = self.fc08(semantic_features)\n",
    "        return semantic_features, p_label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = SemanticImageExtractor(6)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SemanticImageExtractor(\n",
       "  (alx_layer1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (alx_layer2): Sequential(\n",
       "    (0): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (alx_layer3): Sequential(\n",
       "    (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (alx_layer4): Sequential(\n",
       "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (alx_layer5): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (fc06): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc07): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=4096, out_features=200, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc08): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=6, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params_to_update = model.parameters()\n",
    "optimizer = optim.SGD(params_to_update , lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, weights_name='weight_save', is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    loss_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        _,outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        # loss2 = criterion(aux4a, labels)\n",
    "                        # loss3 = criterion(aux4d, labels)\n",
    "                        loss = loss1 #+ (0.3 * loss2) + (0.3 * loss3)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # Backpropagate only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # Gather our summary statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_end = time.time()\n",
    "            \n",
    "            elapsed_epoch = epoch_end - epoch_start\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print(\"Epoch time taken: \", elapsed_epoch)\n",
    "\n",
    "            # If this is the best model on the validation set so far, deep copy it\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), weights_name + \".pth\")\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            if phase == 'train':\n",
    "                loss_acc_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Output summary statistics, load the best weight set, and return results\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, loss_acc_history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataloaders = { 'train': data_loader}\n",
    "best_model, val_acc_history, loss_acc_history = train_model(model, dataloaders, criterion, optimizer, 9000, 'google_softmax_lr_0.001_bestsofar', is_inception=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/8999\n",
      "----------\n",
      "train Loss: 1.5950 Acc: 0.4167\n",
      "Epoch time taken:  0.6492619514465332\n",
      "\n",
      "Epoch 1/8999\n",
      "----------\n",
      "train Loss: 1.6226 Acc: 0.3583\n",
      "Epoch time taken:  0.6904113292694092\n",
      "\n",
      "Epoch 2/8999\n",
      "----------\n",
      "train Loss: 1.5901 Acc: 0.4000\n",
      "Epoch time taken:  0.6369082927703857\n",
      "\n",
      "Epoch 3/8999\n",
      "----------\n",
      "train Loss: 1.5902 Acc: 0.4417\n",
      "Epoch time taken:  0.6552829742431641\n",
      "\n",
      "Epoch 4/8999\n",
      "----------\n",
      "train Loss: 1.6012 Acc: 0.3750\n",
      "Epoch time taken:  0.6684300899505615\n",
      "\n",
      "Epoch 5/8999\n",
      "----------\n",
      "train Loss: 1.6128 Acc: 0.4083\n",
      "Epoch time taken:  0.6652665138244629\n",
      "\n",
      "Epoch 6/8999\n",
      "----------\n",
      "train Loss: 1.6366 Acc: 0.3583\n",
      "Epoch time taken:  0.5855779647827148\n",
      "\n",
      "Epoch 7/8999\n",
      "----------\n",
      "train Loss: 1.6266 Acc: 0.4167\n",
      "Epoch time taken:  0.6230096817016602\n",
      "\n",
      "Epoch 8/8999\n",
      "----------\n",
      "train Loss: 1.5950 Acc: 0.4333\n",
      "Epoch time taken:  0.6874463558197021\n",
      "\n",
      "Epoch 9/8999\n",
      "----------\n",
      "train Loss: 1.6119 Acc: 0.4000\n",
      "Epoch time taken:  0.7001528739929199\n",
      "\n",
      "Epoch 10/8999\n",
      "----------\n",
      "train Loss: 1.6014 Acc: 0.4000\n",
      "Epoch time taken:  0.6189534664154053\n",
      "\n",
      "Epoch 11/8999\n",
      "----------\n",
      "train Loss: 1.6055 Acc: 0.3583\n",
      "Epoch time taken:  0.631598711013794\n",
      "\n",
      "Epoch 12/8999\n",
      "----------\n",
      "train Loss: 1.6076 Acc: 0.3750\n",
      "Epoch time taken:  0.6274375915527344\n",
      "\n",
      "Epoch 13/8999\n",
      "----------\n",
      "train Loss: 1.6235 Acc: 0.3750\n",
      "Epoch time taken:  0.6907780170440674\n",
      "\n",
      "Epoch 14/8999\n",
      "----------\n",
      "train Loss: 1.6050 Acc: 0.3750\n",
      "Epoch time taken:  0.6439964771270752\n",
      "\n",
      "Epoch 15/8999\n",
      "----------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}